{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle \n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor, GradientBoostingRegressor \n",
    "from sklearn.metrics import mean_pinball_loss, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import src.data.preprocessor as pre\n",
    "import src.data.datasets as data\n",
    "import src.helper as h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"CMAPSS2\"\n",
    "cal_portion=0.1\n",
    "exp_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "removable_cols = [\"sm01\", \"sm05\", \"sm06\", \"sm10\", \"sm16\", \"sm18\", \"sm19\"]\n",
    "ignore_columns = [\"time\", \"os1\", \"os2\", \"os3\"]\n",
    "\n",
    "alpha_array = np.array([0.1, 0.15, 0.2, 0.25]) #array of miscoverage rates\n",
    "quantiles = np.concatenate((alpha_array, np.array([0.5]), 1-alpha_array))\n",
    "\n",
    "#load, split, and preprocess the specified dataset \n",
    "dataset = data.get_dataset(dataset_name, MinMaxScaler(feature_range=(-1, 1)))\n",
    "split_dataset = pre.split_dataset(dataset, cal_size=cal_portion, random_state=exp_seed)\n",
    "proc_dataset = pre.preprocess_split(split_dataset, scaler_factory=dataset[\"scaler_factory\"], window_size=1, removable_cols=removable_cols, ignore_columns=ignore_columns)\n",
    "\n",
    "X_train = proc_dataset[\"train\"][\"X\"].reshape((-1,14))\n",
    "y_train = proc_dataset[\"train\"][\"y\"].reshape(-1)\n",
    "X_cal = proc_dataset[\"cal\"][\"X\"].reshape((-1,14))\n",
    "y_cal = proc_dataset[\"cal\"][\"y\"].reshape(-1)\n",
    "idx_cal = proc_dataset[\"cal\"][\"index\"]\n",
    "X_test, y_test, idx_test = h.reform_test_data(proc_dataset[\"test\"])\n",
    "X_test = X_test.reshape((-1,14))\n",
    "y_test = y_test.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mean absolute error of GB: 26.66881209754944\n",
      "calibration mean absolute error of GB: 29.5310719297658\n",
      "training mean absolute error of GB: 22.349861259424983\n",
      "calibration mean absolute error of GB: 24.743663171900366\n",
      "training mean absolute error of GB: 19.592216434914356\n",
      "calibration mean absolute error of GB: 21.438151258104995\n",
      "training mean absolute error of GB: 17.42208411100241\n",
      "calibration mean absolute error of GB: 18.72778628970242\n",
      "training mean absolute error of GB: 13.565645241904358\n",
      "calibration mean absolute error of GB: 13.297863307995026\n",
      "training mean absolute error of GB: 29.711999274825533\n",
      "calibration mean absolute error of GB: 31.412831649806538\n",
      "training mean absolute error of GB: 20.478672458703876\n",
      "calibration mean absolute error of GB: 20.8817155871189\n",
      "training mean absolute error of GB: 19.064353526926233\n",
      "calibration mean absolute error of GB: 19.56339388119991\n",
      "training mean absolute error of GB: 16.872551769465304\n",
      "calibration mean absolute error of GB: 16.99330239191566\n"
     ]
    }
   ],
   "source": [
    "all_models = {}\n",
    "for q in quantiles:\n",
    "    gbr = HistGradientBoostingRegressor(loss=\"quantile\", quantile=q, random_state=exp_seed)\n",
    "    all_models[\"q %1.2f\" % q] = gbr.fit(X_train, y_train)\n",
    "    print(\"training mean absolute error of GB:\", mean_absolute_error(y_train, gbr.predict(X_train)))\n",
    "    print(\"calibration mean absolute error of GB:\", mean_absolute_error(y_cal, gbr.predict(X_cal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mean absolute error of GB: 25.305121821554977\n",
      "calibration mean absolute error of GB: 32.96799273109887\n",
      "training mean absolute error of GB: 21.70427996198666\n",
      "calibration mean absolute error of GB: 28.574233921020188\n",
      "training mean absolute error of GB: 18.648215630889556\n",
      "calibration mean absolute error of GB: 24.534115382544577\n",
      "training mean absolute error of GB: 16.241115179313173\n",
      "calibration mean absolute error of GB: 20.99808849310661\n",
      "training mean absolute error of GB: 12.08646541923864\n",
      "calibration mean absolute error of GB: 11.965019451256707\n",
      "training mean absolute error of GB: 28.11748078478653\n",
      "calibration mean absolute error of GB: 24.267049119346655\n",
      "training mean absolute error of GB: 38.51064985872637\n",
      "calibration mean absolute error of GB: 35.36147283340817\n",
      "training mean absolute error of GB: 17.022445729052915\n",
      "calibration mean absolute error of GB: 14.258710744088434\n",
      "training mean absolute error of GB: 38.51064985872637\n",
      "calibration mean absolute error of GB: 35.36147283340817\n"
     ]
    }
   ],
   "source": [
    "all_models = {}\n",
    "for q in quantiles:\n",
    "    gbr = GradientBoostingRegressor(loss=\"quantile\", alpha=q, random_state=exp_seed, n_estimators=500)\n",
    "    all_models[\"q %1.2f\" % q] = gbr.fit(X_train, y_train)\n",
    "    print(\"training mean absolute error of GB:\", mean_absolute_error(y_train, gbr.predict(X_train)))\n",
    "    print(\"calibration mean absolute error of GB:\", mean_absolute_error(y_cal, gbr.predict(X_cal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mean absolute error of GB: 13.99311732443111\n",
      "calibration mean absolute error of GB: 14.035084814355077\n"
     ]
    }
   ],
   "source": [
    "gbr_ls = HistGradientBoostingRegressor(loss=\"squared_error\", random_state=exp_seed)\n",
    "all_models[\"mse\"] = gbr_ls.fit(X_train, y_train)\n",
    "print(\"training mean absolute error of GB:\", mean_absolute_error(y_train, gbr_ls.predict(X_train)))\n",
    "print(\"calibration mean absolute error of GB:\", mean_absolute_error(y_cal, gbr_ls.predict(X_cal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mean absolute error of GB: 15.889087368742244\n",
      "calibration mean absolute error of GB: 14.49726354484342\n"
     ]
    }
   ],
   "source": [
    "gbr_ls = GradientBoostingRegressor(loss=\"squared_error\", random_state=exp_seed)\n",
    "all_models[\"mse\"] = gbr_ls.fit(X_train, y_train)\n",
    "print(\"training mean absolute error of GB:\", mean_absolute_error(y_train, gbr_ls.predict(X_train)))\n",
    "print(\"calibration mean absolute error of GB:\", mean_absolute_error(y_test, gbr_ls.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mean absolute error of GB: 20.569370613427434\n",
      "calibration mean absolute error of GB: 18.49255816955265\n"
     ]
    }
   ],
   "source": [
    "gbr_ls = GradientBoostingRegressor(loss=\"squared_error\", random_state=exp_seed)\n",
    "all_models[\"mse\"] = gbr_ls.fit(X_train, y_train)\n",
    "print(\"training mean absolute error of GB:\", np.sqrt(mean_squared_error(y_train, gbr_ls.predict(X_train))))\n",
    "print(\"calibration mean absolute error of GB:\", np.sqrt(mean_squared_error(y_test, gbr_ls.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = gbr_ls.predict(X_train)\n",
    "y_hat_cal = gbr_ls.predict(X_cal)\n",
    "y_hat_test = gbr_ls.predict(X_test)\n",
    "res_train = np.abs(y_hat_train - y_train) \n",
    "res_cal = np.abs(y_hat_cal - y_cal) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest details:\n",
      "average labels (training absolute residuals of DCNN): 13.99311732443111\n",
      "training mean absolute error of RF: 2.7705612547223555\n",
      "calibration mean absolute error of RF: 7.497478684194068\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestRegressor(random_state=exp_seed) \n",
    "RF.fit(X_train, res_train)\n",
    "print(\"Random forest details:\")\n",
    "print(\"average labels (training absolute residuals of DCNN):\", res_train.mean())\n",
    "print(\"training mean absolute error of RF:\", mean_absolute_error(res_train, RF.predict(X_train)))\n",
    "print(\"calibration mean absolute error of RF:\", mean_absolute_error(res_cal, RF.predict(X_cal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_cal = RF.predict(X_cal)\n",
    "sigma_test = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_cal_CQR ={}\n",
    "y_hat_test_CQR ={}\n",
    "for q in quantiles:\n",
    "    y_hat_cal_CQR[\"q %1.2f\" % q] = all_models[\"q %1.2f\" % q].predict(X_cal)\n",
    "    y_hat_test_CQR[\"q %1.2f\" % q] = all_models[\"q %1.2f\" % q].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.abs(y_cal - y_hat_cal) \n",
    "scores_normalized = scores/sigma_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "(0.9382239382239382, 0.918918918918919, 58.78011321744518)\n",
      "(0.9111969111969112, 0.8725868725868726, 49.50239916232735)\n",
      "(0.9420849420849421, 0.9305019305019305, 60.66245336778787)\n",
      "(0.9266409266409267, 0.8918918918918919, 50.99596635170149)\n",
      "(0.918918918918919, 0.8996138996138996, 63.28153906901978)\n",
      "0.15\n",
      "(0.9227799227799228, 0.8725868725868726, 49.828786725592174)\n",
      "(0.8841698841698842, 0.8108108108108109, 42.0913736009775)\n",
      "(0.9227799227799228, 0.8764478764478765, 51.04677944164962)\n",
      "(0.9034749034749034, 0.8455598455598455, 43.36336093364902)\n",
      "(0.8957528957528957, 0.8455598455598455, 44.710219703082906)\n",
      "0.2\n",
      "(0.8957528957528957, 0.8378378378378378, 43.11205170901882)\n",
      "(0.8571428571428571, 0.7374517374517374, 37.17751237689024)\n",
      "(0.9073359073359073, 0.8494208494208494, 44.14483138378495)\n",
      "(0.8725868725868726, 0.7606177606177607, 38.165004118170785)\n",
      "(0.8532818532818532, 0.7799227799227799, 38.729309777153304)\n",
      "0.25\n",
      "(0.8687258687258688, 0.7722007722007722, 38.30273130622482)\n",
      "(0.8416988416988417, 0.7142857142857143, 33.33003989581309)\n",
      "(0.8803088803088803, 0.7953667953667953, 39.2339160028893)\n",
      "(0.8416988416988417, 0.7142857142857143, 34.25340250443635)\n",
      "(0.8185328185328186, 0.7374517374517374, 33.11275538567013)\n"
     ]
    }
   ],
   "source": [
    "rho = 0.99\n",
    "for i in range(len(alpha_array)):\n",
    "    alpha = alpha_array[i]\n",
    "    q = h.compute_quantile(scores, alpha)\n",
    "    q_array = h.compute_quantiles_nex(rho, scores.reshape((-1,1)), idx_test, idx_cal, alpha).reshape(-1)\n",
    "    q_normalized = h.compute_quantile(scores_normalized, alpha)\n",
    "    q_array_normalized = h.compute_quantiles_nex(rho, scores_normalized.reshape((-1,1)), idx_test, idx_cal, alpha).reshape(-1)\n",
    "\n",
    "\n",
    "    scores_low = y_hat_cal_CQR[\"q %1.2f\" % alpha] - y_cal\n",
    "    scores_high = y_cal - y_hat_cal_CQR[\"q %1.2f\" % (1-alpha)] \n",
    "    scores_CQR = np.maximum(scores_low, scores_high)\n",
    "    q_CQR = h.compute_quantile(scores_CQR, alpha)\n",
    "    print(alpha)\n",
    "    print(h.compute_coverage_len(y_test, np.maximum(0,y_hat_test - q), y_hat_test + q))\n",
    "    print(h.compute_coverage_len(y_test, np.maximum(0,y_hat_test - q_normalized*sigma_test), y_hat_test + q_normalized*sigma_test))\n",
    "    print(h.compute_coverage_len(y_test, np.maximum(0, y_hat_test  - q_array), y_hat_test  + q_array))\n",
    "    print(h.compute_coverage_len(y_test, np.maximum(0, y_hat_test  - q_array_normalized*sigma_test), y_hat_test  + q_array_normalized*sigma_test))\n",
    "    print(h.compute_coverage_len(y_test, np.maximum(0, y_hat_test_CQR[\"q %1.2f\" % alpha] - q_CQR), y_hat_test_CQR[\"q %1.2f\" % (1-alpha)]  + q_CQR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = q_array_normalized*sigma_test\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18404,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('rul_unc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ed615bccc073c0a0281f121b591de3b0f9d3533c6b13e0905cf5e0bb75735d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
